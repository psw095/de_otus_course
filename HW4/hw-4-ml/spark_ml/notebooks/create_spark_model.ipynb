{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current spark version is 3.0.0\n"
     ]
    }
   ],
   "source": [
    "println(s\"Current spark version is ${spark.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|    1|800000|\n",
      "|    0|800000|\n",
      "+-----+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.types.{StructType, StructField, IntegerType, LongType, StringType}\n",
       "dataSchema: org.apache.spark.sql.types.StructType = StructType(StructField(target,IntegerType,true), StructField(id,LongType,true), StructField(raw_timestamp,StringType,true), StructField(query_status,StringType,true), StructField(author,StringType,true), StructField(tweet,StringType,true))\n",
       "dataPath: String = ./home/jovyan/data/training.1600000.processed.noemoticon.csv\n",
       "raw_sentiment: org.apache.spark.sql.DataFrame = [label: int, tweet: string]\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types.{StructType, StructField, IntegerType, LongType, StringType}\n",
    "\n",
    "val dataSchema = new StructType()\n",
    "    .add(\"target\", IntegerType)\n",
    "    .add(\"id\", LongType)\n",
    "    .add(\"raw_timestamp\", StringType)\n",
    "    .add(\"query_status\", StringType)\n",
    "    .add(\"author\", StringType)\n",
    "    .add(\"tweet\", StringType)\n",
    "\n",
    "val dataPath= \"./home/jovyan/data/training.1600000.processed.noemoticon.csv\"\n",
    "\n",
    "val raw_sentiment = spark.read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\",false)\n",
    "    .schema(dataSchema)\n",
    "    .load(dataPath)\n",
    "    .selectExpr(\"(case when target=4 then 1 else 0 end) as label\",\"tweet\")\n",
    "\n",
    "raw_sentiment.groupBy($\"label\").count.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
       "import org.apache.spark.ml.classification.LogisticRegression\n",
       "import org.apache.spark.ml.feature.{HashingTF, Tokenizer}\n",
       "import org.apache.spark.ml.linalg.Vector\n",
       "import org.apache.spark.sql.Row\n",
       "tokenizer: org.apache.spark.ml.feature.Tokenizer = tok_91d03ec80849\n",
       "hashingTF: org.apache.spark.ml.feature.HashingTF = HashingTF: uid=hashingTF_f2da4c434deb, binary=false, numFeatures=1000\n",
       "lr: org.apache.spark.ml.classification.LogisticRegression = logreg_abfff0af24ac\n",
       "pipeline: org.apache.spark.ml.Pipeline = pipeline_c1060c847dd2\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
    "import org.apache.spark.ml.classification.LogisticRegression\n",
    "\n",
    "\n",
    "import org.apache.spark.ml.feature.{HashingTF, Tokenizer}\n",
    "import org.apache.spark.ml.linalg.Vector\n",
    "import org.apache.spark.sql.Row\n",
    "\n",
    "\n",
    "val tokenizer = new Tokenizer()\n",
    "    .setInputCol(\"tweet\")\n",
    "    .setOutputCol(\"words\")\n",
    "\n",
    "val hashingTF = new HashingTF()\n",
    "    .setNumFeatures(1000)\n",
    "    .setInputCol(tokenizer.getOutputCol)\n",
    "    .setOutputCol(\"features\")\n",
    "\n",
    "val lr = new LogisticRegression()\n",
    "    .setMaxIter(10)\n",
    "    .setRegParam(0.001)\n",
    "\n",
    "\n",
    "val pipeline = new Pipeline()\n",
    "  .setStages(Array(tokenizer, hashingTF, lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.Pipeline\n",
       "import org.apache.spark.ml.classification.{RandomForestClassificationModel, RandomForestClassifier}\n",
       "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
       "import org.apache.spark.ml.feature.{IndexToString, StringIndexer, VectorIndexer}\n",
       "tokenizer: org.apache.spark.ml.feature.Tokenizer = tok_4ec0fe5aa0da\n",
       "hashingTF: org.apache.spark.ml.feature.HashingTF = HashingTF: uid=hashingTF_f67c2e516f83, binary=false, numFeatures=1000\n",
       "rf: org.apache.spark.ml.classification.RandomForestClassifier = rfc_5a56f6eb6362\n",
       "pipeline: org.apache.spark.ml.Pipeline = pipeline_fbfca867f926\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.Pipeline\n",
    "import org.apache.spark.ml.classification.{RandomForestClassificationModel, RandomForestClassifier}\n",
    "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
    "import org.apache.spark.ml.feature.{IndexToString, StringIndexer, VectorIndexer}\n",
    "\n",
    "\n",
    "val tokenizer = new Tokenizer()\n",
    "    .setInputCol(\"tweet\")\n",
    "    .setOutputCol(\"words\")\n",
    "\n",
    "val hashingTF = new HashingTF()\n",
    "    .setNumFeatures(1000)\n",
    "    .setInputCol(tokenizer.getOutputCol)\n",
    "    .setOutputCol(\"features\")\n",
    "\n",
    "// Train a RandomForest model.\n",
    "val rf = new RandomForestClassifier()\n",
    "  .setLabelCol(\"indexedLabel\")\n",
    "  .setFeaturesCol(\"indexedFeatures\")\n",
    "  .setNumTrees(10)\n",
    "\n",
    "val pipeline = new Pipeline()\n",
    "  .setStages(Array(tokenizer, hashingTF, rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "java.lang.IllegalArgumentException",
     "evalue": " indexedFeatures does not exist. Available: label, tweet, words, features",
     "output_type": "error",
     "traceback": [
      "java.lang.IllegalArgumentException: indexedFeatures does not exist. Available: label, tweet, words, features",
      "  at org.apache.spark.sql.types.StructType.$anonfun$apply$1(StructType.scala:278)",
      "  at scala.collection.immutable.Map$Map4.getOrElse(Map.scala:220)",
      "  at org.apache.spark.sql.types.StructType.apply(StructType.scala:277)",
      "  at org.apache.spark.ml.util.SchemaUtils$.checkColumnType(SchemaUtils.scala:42)",
      "  at org.apache.spark.ml.PredictorParams.validateAndTransformSchema(Predictor.scala:51)",
      "  at org.apache.spark.ml.PredictorParams.validateAndTransformSchema$(Predictor.scala:46)",
      "  at org.apache.spark.ml.classification.Classifier.org$apache$spark$ml$classification$ClassifierParams$$super$validateAndTransformSchema(Classifier.scala:72)",
      "  at org.apache.spark.ml.classification.ClassifierParams.validateAndTransformSchema(Classifier.scala:42)",
      "  at org.apache.spark.ml.classification.ClassifierParams.validateAndTransformSchema$(Classifier.scala:38)",
      "  at org.apache.spark.ml.classification.ProbabilisticClassifier.org$apache$spark$ml$classification$ProbabilisticClassifierParams$$super$validateAndTransformSchema(ProbabilisticClassifier.scala:50)",
      "  at org.apache.spark.ml.classification.ProbabilisticClassifierParams.validateAndTransformSchema(ProbabilisticClassifier.scala:37)",
      "  at org.apache.spark.ml.classification.ProbabilisticClassifierParams.validateAndTransformSchema$(ProbabilisticClassifier.scala:33)",
      "  at org.apache.spark.ml.classification.RandomForestClassifier.org$apache$spark$ml$tree$TreeEnsembleClassifierParams$$super$validateAndTransformSchema(RandomForestClassifier.scala:46)",
      "  at org.apache.spark.ml.tree.TreeEnsembleClassifierParams.validateAndTransformSchema(treeParams.scala:405)",
      "  at org.apache.spark.ml.tree.TreeEnsembleClassifierParams.validateAndTransformSchema$(treeParams.scala:401)",
      "  at org.apache.spark.ml.classification.RandomForestClassifier.validateAndTransformSchema(RandomForestClassifier.scala:46)",
      "  at org.apache.spark.ml.Predictor.transformSchema(Predictor.scala:176)",
      "  at org.apache.spark.ml.Pipeline.$anonfun$transformSchema$4(Pipeline.scala:183)",
      "  at scala.collection.IndexedSeqOptimized.foldLeft(IndexedSeqOptimized.scala:60)",
      "  at scala.collection.IndexedSeqOptimized.foldLeft$(IndexedSeqOptimized.scala:68)",
      "  at scala.collection.mutable.ArrayOps$ofRef.foldLeft(ArrayOps.scala:198)",
      "  at org.apache.spark.ml.Pipeline.transformSchema(Pipeline.scala:183)",
      "  at org.apache.spark.ml.PipelineStage.transformSchema(Pipeline.scala:71)",
      "  at org.apache.spark.ml.Pipeline.$anonfun$fit$2(Pipeline.scala:134)",
      "  at org.apache.spark.ml.MLEvents.withFitEvent(events.scala:132)",
      "  at org.apache.spark.ml.MLEvents.withFitEvent$(events.scala:125)",
      "  at org.apache.spark.ml.util.Instrumentation.withFitEvent(Instrumentation.scala:42)",
      "  at org.apache.spark.ml.Pipeline.$anonfun$fit$1(Pipeline.scala:133)",
      "  at org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)",
      "  at scala.util.Try$.apply(Try.scala:213)",
      "  at org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)",
      "  at org.apache.spark.ml.Pipeline.fit(Pipeline.scala:133)",
      "  ... 41 elided",
      ""
     ]
    }
   ],
   "source": [
    "val model = pipeline.fit(raw_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.write.overwrite().save(\"./home/jovyan/models/spark-ml-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sameModel: org.apache.spark.ml.PipelineModel = pipeline_6134807c4a40\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sameModel = PipelineModel.load(\"./home/jovyan/models/spark-ml-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|label|               tweet|               words|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|    0|@switchfoot http:...|[@switchfoot, htt...|(1000,[10,21,81,1...|[-1.7093077824653...|[0.15325352111538...|       1.0|\n",
      "|    0|is upset that he ...|[is, upset, that,...|(1000,[121,193,20...|[0.98452561467195...|[0.72800527368281...|       0.0|\n",
      "|    0|@Kenichan I dived...|[@kenichan, i, di...|(1000,[17,185,188...|[-0.2839685001973...|[0.42948111509142...|       1.0|\n",
      "|    0|my whole body fee...|[my, whole, body,...|(1000,[191,330,44...|[0.15558576510068...|[0.53881816712715...|       0.0|\n",
      "|    0|@nationwideclass ...|[@nationwideclass...|(1000,[32,162,166...|[2.91879438070485...|[0.94876772860820...|       0.0|\n",
      "|    0|@Kwesidei not the...|[@kwesidei, not, ...|(1000,[17,205,405...|[0.54684040473535...|[0.63340223056144...|       0.0|\n",
      "|    0|         Need a hug |      [need, a, hug]|(1000,[467,537,73...|[0.36581025043152...|[0.59044620062128...|       0.0|\n",
      "|    0|@LOLTrish hey  lo...|[@loltrish, hey, ...|(1000,[157,166,26...|[-2.2145264314778...|[0.09845357411849...|       1.0|\n",
      "|    0|@Tatiana_K nope t...|[@tatiana_k, nope...|(1000,[48,234,257...|[0.40580398619751...|[0.60008132798463...|       0.0|\n",
      "|    0|@twittera que me ...|[@twittera, que, ...|(1000,[67,369,451...|[0.34235670390037...|[0.58476288066157...|       0.0|\n",
      "|    0|spring break in p...|[spring, break, i...|(1000,[207,437,64...|[-0.5788485558931...|[0.35919758395247...|       1.0|\n",
      "|    0|I just re-pierced...|[i, just, re-pier...|(1000,[307,406,47...|[-0.0668739047022...|[0.48328775162407...|       1.0|\n",
      "|    0|@caregiving I cou...|[@caregiving, i, ...|(1000,[17,55,329,...|[-0.1326815310107...|[0.46687819375899...|       1.0|\n",
      "|    0|@octolinz16 It it...|[@octolinz16, it,...|(1000,[32,281,338...|[0.59494885654078...|[0.64449983581387...|       0.0|\n",
      "|    0|@smarrison i woul...|[@smarrison, i, w...|(1000,[17,74,112,...|[2.87104849332323...|[0.94639656307496...|       0.0|\n",
      "|    0|@iamjazzyfizzle I...|[@iamjazzyfizzle,...|(1000,[10,17,54,6...|[2.15230498765454...|[0.89588397290560...|       0.0|\n",
      "|    0|Hollis' death sce...|[hollis', death, ...|(1000,[3,58,109,1...|[0.62960016250125...|[0.65239879472696...|       0.0|\n",
      "|    0|about to file taxes |[about, to, file,...|(1000,[108,294,48...|[0.30918068337461...|[0.57668526265021...|       0.0|\n",
      "|    0|@LettyA ahh ive a...|[@lettya, ahh, iv...|(1000,[11,17,240,...|[-0.4919580582516...|[0.37943240777197...|       1.0|\n",
      "|    0|@FakerPattyPattz ...|[@fakerpattypattz...|(1000,[2,17,216,2...|[-0.5149322758780...|[0.37403799858886...|       1.0|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "predictionsDF: org.apache.spark.sql.DataFrame = [label: int, tweet: string ... 5 more fields]\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val predictionsDF = sameModel.transform(raw_sentiment)\n",
    "\n",
    "predictionsDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: integer (nullable = false)\n",
      " |-- tweet: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// predictionsDF.schema\n",
    "// predictionsDF.describe()\n",
    "// predictionsDF.stat\n",
    "predictionsDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions._\n",
       "getProbability: org.apache.spark.sql.expressions.UserDefinedFunction = SparkUserDefinedFunction($Lambda$4582/0x0000000841566840@1caba1d6,DoubleType,List(Some(class[value[0]: vector])),None,false,true)\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "val getProbability = udf((prediction: org.apache.spark.ml.linalg.Vector) => prediction(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|   clean_probability|\n",
      "+--------------------+\n",
      "|  0.8467464788846125|\n",
      "| 0.27199472631718885|\n",
      "|  0.5705188849085758|\n",
      "| 0.46118183287284903|\n",
      "| 0.05123227139179534|\n",
      "|  0.3665977694385508|\n",
      "| 0.40955379937871456|\n",
      "|  0.9015464258815026|\n",
      "|  0.3999186720153602|\n",
      "|  0.4152371193384253|\n",
      "|  0.6408024160475245|\n",
      "|  0.5167122483759258|\n",
      "|  0.5331218062410026|\n",
      "|  0.3555001641861205|\n",
      "|0.053603436925034276|\n",
      "| 0.10411602709439732|\n",
      "|  0.3476012052730357|\n",
      "|  0.4233147373497812|\n",
      "|   0.620567592228023|\n",
      "|  0.6259620014111376|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictionsDF.select(getProbability($\"probability\").alias(\"clean_probability\")).show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
